# 引擎分类

这里主要对比一下MyISAM和InnoDB

## 磁盘文件的对比

其中使用`MyISAM`引擎的表：`zz_myisam_index`，会在本地生成三个磁盘文件：

- `zz_myisam_index.frm`：该文件中存储表的结构信息。
- `zz_myisam_index.MYD`：该文件中存储表的行数据。
- `zz_myisam_index.MYI`：该文件中存储表的索引数据。

而反观使用`InnoDB`引擎的表：`zz_innodb_index`，在磁盘中仅有两个文件：

- `zz_innodb_index.frm`：该文件中存储表的结构信息。
- `zz_innodb_index.ibd`：该文件中存储表的行数据和索引数据。

## 索引支持的对比

因为`MyISAM`引擎在设计之初，会将表分为`.frm、.MYD、.MYI`三个文件放在磁盘存储，表数据和索引数据是分别放在`.MYD、.MYI`文件中，所以注定了`MyISAM`引擎只支持非聚簇索引。而`InnoDB`引擎的表数据、索引数据都放在`.ibd`文件中存储，因此`InnoDB`是支持聚簇索引的。

聚簇索引的要求是：索引键和行数据必须在物理空间上也是连续的，而`MyISAM`表数据和索引数据，分别位于两个磁盘文件中，这也就注定了它无法满足聚簇索引的要求。

但不支持聚簇索引也有好处，也就是无论走任何索引，都只需要一遍查询即可获得数据，而`InnoDB`引擎的表中，如果不走聚簇（主键）索引查询数据，走其他索引的情况下，都需要经过两遍（回表）查询才能获得数据（覆盖索引除外）。

## 事务机制的对比

`InnoDB`引擎中有两个自己专享的日志，即`undo-log、redo-log`，先来说说`undo-log`日志，`InnoDB`在`MySQL`启动后，会在内存中构建一个`undo_log_buffer`缓冲区，同时在磁盘中也有相应的`undo-log`日志文件。

一条写入类型的`SQL`语句，在正式执行前都会先记录`redo-log、undo-log`日志，`undo-log`中会记录变更前的旧数据，当一个事务提交时，`MySQL`会正常的将数据落盘，而当一个事务碰到`rollback`命令需要回滚时，就会找到`undo-log`中记录的旧数据，接着用来覆盖变更过的新数据，以此做到将数据回滚到变更前的“样貌”。

> 使用`InnoDB`存储引擎的表，可以借助`undo-log`日志实现事务机制，支持多条`SQL`组成一个事务，可以保证发生异常的情况下，组成这个事务的`SQL`到底回滚还是提交。而`MyISAM`并未设计类似的技术，在启动时不会在内存中构建`undo_log_buffer`缓冲区，磁盘中也没有相应的日志文件，因此`MyISAM`并不支持事务机制。

如果表结构用了`MyISAM`引擎，想要解决这类问题，就只能在客户端做事务补偿，当执行出现异常了，就在客户端中记录一下，然后再向`MySQL`发送一条相应的反`SQL`，以此来保障数据的一致性。

InnoDB借助undo-log保证了事务的原子性

## 故障恢复的对比

`InnoDB`在启动时，同样会在内存中构建一个`redo_log_buffer`缓冲区，在磁盘中也会有相应的`redo-log`日志文件，所以当一条或多条`SQL`语句执行成功后，不论`MySQL`在何时宕机，只要这个事务提交了，`InnoDB`引擎都能确保该事务的数据不会丢失，也就以此保障了事务的持久性。

`InnoDB`引擎由于`redo-log`日志的存在，因此只要事务提交，机器断电、程序宕机等各种灾难情况，都可以用`redo-log`日志来恢复数据。但`MyISAM`引擎同样没有`redo-log`日志，所以并不支持数据的故障恢复，如果表是使用`MyISAM`引擎创建的，当一条`SQL`将数据写入到了缓冲区后，`SQL`还未被写到`bin-log`日志，此时机器断电、`DB`宕机了，重启之后由于数据在宕机前还未落盘，所以丢了也就无法找回。

> 从这一点来说，`MyISAM`并没有`InnoDB`引擎可靠，在`InnoDB`中只要事务提交，它就能确保数据永远不丢失，但`MyISAM`不行。

## 锁粒度的对比

`MyISAM`只支持表锁, 没有实现行级锁

`InnoDB`支持行锁, 因为它的聚簇索引使得加行锁非常容易实现,所有的次级索引，其索引值都存储聚簇索引的索引键，因此想要对一行数据加锁时，只需要锁定聚簇索引的数据即可。对于覆盖索引, 如果更新聚簇索引的时候, 也会对对应的覆盖索引上锁



## 并发性能的对比

`MyISAM`仅支持表锁，`InnoDB`同时支持表锁、行锁，由于这点原因，其实`InnoDB`引擎的并发支持性早已远超`MyISAM`了，毕竟锁的粒度越小，并发冲突的概率也就越低，因此并发支撑就越高。

> 但是`InnoDB`不仅仅只满足于此，为了提升读-写并存场景下的并发度，`InnoDB`引擎又基于`undo-log`日志的版本链+事务快照，又推出了`MVCC`多版本并发控制技术，因此对于读-写共存的场景支持并发执行。

但`MyISAM`只支持表锁，因此当一条`SQL`在写数据时，其他`SQL`就算是来读数据的，也需要阻塞等待，为啥呢？因为写数据时需要加排他锁，这是一种独占类型的锁，会排斥一切尝试获取锁的线程，反过来也是同理，当一条线程在读数据时，另一条线程来写数据，依旧会陷入阻塞等待，毕竟写数据要获取排他锁，也就意味着整张表只允许这一个线程操作

## 内存利用度的对比

全部都放在了内存中完成，无论是读写数据、维护索引结构也好，记录日志也罢，各类操作全部都在内存完成。

只要你机器的内存够大，为缓冲池分配的内存够多，`MySQL`在线上运行的时间够久，`InnoDB`甚至会将磁盘中的所有数据，全部载入内存，然后所有客户端的读写请求，基本上无需再走磁盘来完成，都采用异步`IO`的方式完成，即先写内存+后台线程刷写的方式执行，后台线程的刷盘动作，对客户端而言不会有任何感知，在写完内存之后就会直接向客户端返回。

而MyISAM还是基于磁盘的,内部虽然也有缓冲池以及异步`IO`技术，但对内存的开发度远不足于`InnoDB`引擎，运行期间大量操作依旧会走磁盘完成。对于很多操作都是托付server层实现的, 比如查询缓存

## MyISAM的优势

- 在统计表的总行数时, 由于MyISAM会记录表的行数, 而InnoDB需要全表扫描, 所以MyISAM更快, 但也仅限于统计表的总记录数

- 对于删除表, `MyISAM`会直接重新创建表数据文件，而`InnoDB`则是一行行删除数据

- 同时`MyISAM`引擎的表，对于`delete`过的数据不会立即删除，而且先隐藏起来，后续定时删除或手动删除，手动强制清理的命令如下：

  ```sql
  sql
  复制代码optimize table `table_name`;
  ```

  这样做有一点好处，就是当你误删一张表的大量数据时，只要你手速够快，手动将本地的`.MYD、.MYI`文件拷贝出去，就可以直接基于这两个数据文件恢复数据，而不需要通过日志或第三方工具修复数据。

- 而`MyISAM`引擎中，所有已创建的索引都是非聚簇索引，每个索引之间都是独立的，在索引中存储的是直接指向行数据的地址，而并非聚簇索引的索引键，因此无论走任何索引，都仅需一次即可获得数据，无需做回表查询。

  同时写数据时，也不需要维护不同索引之间的关系，毕竟每个索引都是独立的，因此`MyISAM`在理论上，读写数据的效率会高于`InnoDB`引擎。

  但是在高并发的情况, 就不再适用.如果以单连接的方式测试，确实`MyISAM`会远超`InnoDB`，毕竟单个连接意味着只有一条线程，一条线程就不会出现锁竞争，表锁会一直由这条线程持有

### MyISAM适用场景

结合`MyISAM`引擎的特性而言，它适用于一些不需要事务、并发冲突低、读操作多的表，例如文章表、帖子表、字典表....

有一种场景时，特别适合使用`MyISAM`引擎，即`MySQL`利用主从架构，实现读写分离时的场景，一般从库会承载`select`请求，而主库会承载`insert/update/delete`请求。读写分离的场景中，从库的表结构可以改为`MyISAM`引擎，因为基于`MyISAM`的索引查询数据，不需要经过回表查询，速度更快！而且从库的数据是由后台线程来从主库复制的，因此从库在写入数据时，只会有少数几条线程执行写入工作，因而造成的冲突不会太大，不会由于表锁引起大量阻塞。

## 总结

1. 存储方式： MyISAM会将数据和索引分开存储，InnoDB在聚簇索引上索引和数据是一起存储的
2. 索引支持：MyISAM不支持聚簇索引
3. 事务支持：由于`MyISAM`引擎没有`undo-log`日志，所以不支持多条`SQL`组成事务并回滚。
4. 故障恢复：`MyISAM`引擎依靠`bin-log`日志实现，`bin-log`中未写入的数据会永久丢失
5. 锁粒度支持：`MyISAM`不支持聚簇索引，因此没有实现行锁，所有并发操作只能加表锁
6. 并发性能：`MyISAM`仅支持表锁,所以多条线程出现读-写并发场景时会阻塞。
7. 内存利用度：`MyISAM`引擎过于依赖`MySQL Server`，对缓冲池、异步`IO`技术开发度不够。

# 一条select语句的执行过程

![mysql查询流程](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\mysql查询流程.webp)

- 连接器：负责建立连接、管理连接、验证用户身份
- 查询缓存：如果查询命中查询缓存则直接返回，否则继续往下执行。MySQL8.0后删除该模块
- 解析器：通过词法分析、语法分析构建语法树
- 执行SQL，执行SQL分为三个阶段：
  - prepare预处理阶段：判断语句中的表和字段是否存在；将*扩充到该表的所有字段
  - optimize优化阶段：根据查询成本，选择成本最小的查询方案，生成执行计划
  - execute执行阶段：根据执行计划执行SQL语句，从存储引擎读取记录，返回给客户端

# MySQL一行记录是如何存储的

## 表空间文件结构

![img](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\表空间结构.drawio.png)

- 行（row）：记录都是按行存储，每行记录行格式不同，存储结构也不同
- 页（page）：InnoDB数据是按页为单位读写，默认每个页大小为16KB
- 区（extent）：表中数据量大时，为某个索引分配空间就不再按照页为单位分配了，而是按照区。每个区大小为1MB， 64个连续的16KB大小的页会被划分为一个区，使得B+树链表中相邻的页物理位置也相邻，就可以使用顺序IO
- 段（segment）：
  - 索引段：存放B+树非叶子节点的区的集合
  - 数据段：存放B+树叶子节点的区的集合
  - 回滚段：回滚数据的区的集合

## InnoDB行格式有哪些

- Redundant: MySQL5.0之前用的不紧凑的行格式，现在基本没人用
- Compact：Compact是一种紧凑的行格式， 设计初衷是为了一个数据页存放更多行记录，5.1之后默认Compact
- Dynamic和Compressed：都是紧凑的行格式， 只是在处理行溢出策略不同

## Compact行格式



![img](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\COMPACT.drawio.png)

### 记录的额外信息



#### 变长字段长度列表

用来记录varchar、TEXT、BLOB等变长字段的数据大小, 值为该字段占用的字节数。

- 变长字段长度列表会按列的顺序逆序存放
- 不需要保存值为NULL的变长字段的长度

> 为什么逆序存放？

主要是因为记录头信息中指向下一条记录的指针，指向的是记录头信息和记录的真实数据之间的位置（这样向左读就是记录头信息，向右读就是真实数据）。

而变长字段长度列表的信息逆序存放，真实数据中靠前的变长字段，和数据对应的变长字段长度信息可以在同一个CPU Cache Line中，就能提高CPU cache命中率

> 每个数据库表的行格式都有变长字段长度列表吗?

只会出现在表中有变长字段的时候



#### NULL值列表

如果存在允许NULL值的列, 每个列对应一个二进制位, 按列的顺序逆序排放在NULL值列表

- 值为1时该列为NULL, 值为0时该列不为NULL
- NULL值列表长度为整数个字节,如果二进制位个数不足整数个字节,则在字节高位补0

> 每个数据库表的行格式都有NULL值列表吗

不是必须的, 当字段都为NOT NULL时, 表里的行格式就不会有NULL值列表

> 「NULL 值列表」是固定 1 字节空间吗？如果这样的话，一条记录有 9 个字段值都是 NULL，这时候怎么表示？

「NULL 值列表」的空间不是固定 1 字节的。

当一条记录有 9 个字段值都是 NULL，那么就会创建 2 字节空间的「NULL 值列表」，以此类推



#### 记录头信息

- delete_mask: 标识这条记录是否被删除. 执行delete删除记录的时候, 并不会真正



# 事务隔离级别和MVCC

## 事务隔离级别

### 事务并发执行遇到的问题

- 脏写

  ![image_1d8nigfq618jd1cc56231rt0uq19.png-78.2kB](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\9dbb2113ed2744b99f599b5fc1b2bb32tplv-k3u1fbpfcp-jj-mark1890000q75.webp)

  脏写就是对当前记录进行update, 因为有其他事务对这条记录并发执行, 并且发生了回滚, 所以当前事务commit之后记录并没有更新

- 脏读

  ![image_1d8nn50kndkd8641epplvelhk9.png-91.8kB](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\0e14e4fe30664ae398a29fba855afda8tplv-k3u1fbpfcp-jj-mark1890000q75.webp)

  脏读就是读取到了其他未提交事务修改过的数据

- 不可重复读

  ![image_1d8nk4k1e1mt51nsj1hg41cd7v5950.png-139.4kB](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\2be4b2847fe64c4cb0d5db1a5505bd2atplv-k3u1fbpfcp-jj-mark1890000q75.webp)

  就是当前事务对同一条记录查询,每次查询的结果都不一样, 原因是有其他已提交事务对这条记录进行了修改(删改)

- 幻读

  ![image_1d8nl564faluogc1eqn1am812v79.png-96.1kB](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\8c5bef4507364a04854a088f68ba6c90tplv-k3u1fbpfcp-jj-mark1890000q75.webp)

  `幻读`强调的是一个事务按照某个相同条件多次读取记录时，后读取时读到了之前没有读到的记录。

  > 那对于先前已经读到的记录，之后又读取不到这种情况，算啥呢？其实这相当于对每一条记录都发生了不可重复读的现象。幻读只是重点强调了读取到了之前读取没有获取到的记录。

### SQL标准中四种隔离级别

问题严重性:

` 脏写 > 脏读 > 不可重复读 > 幻读 `

提出下面四种隔离级别:

 

| **隔离级别**       | 脏写         | 脏读         | 不可重复读   | 幻读         |
| ------------------ | ------------ | ------------ | ------------ | ------------ |
| `READ UNCOMMITTED` | Not Possible | Possible     | Possible     | Possible     |
| `READ COMMITTED`   | Not Possible | Not Possible | Possible     | Possible     |
| `REPEATABLE READ`  | Not Possible | Not Possible | Not Possible | Possible     |
| `SERIALIZABLE`     | Not Possible | Not Possible | Not Possible | Not Possible |

> `MySQL`的默认隔离级别为`REPEATABLE READ`  

## MVCC原理

### 版本链

对于InnoDB, 它的聚簇索引都含有下面两个必要的隐藏列:

- `trx_id`：每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的`事务id`赋值给`trx_id`隐藏列。
- `roll_pointer`：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到`undo日志`中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。

通过这两个隐藏列, 就可以实现版本链. 每次对记录进行改动, 都会生成一条undo log, 每条undo log也都有roll_pointer属性,(`INSERT`操作对应的`undo日志`没有该属性，因为该记录并没有更早的版本), 将这些undo log连起来串成链表

![image_1d8po6kgkejilj2g4t3t81evm20.png-81.7kB](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\16a33e277a98dbectplv-t2oaga2asx-jj-mark1890000q75.webp)

对该记录每次更新后，都会将旧值放到一条`undo日志`中，就算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被`roll_pointer`属性连接成一个链表，我们把这个链表称之为`版本链`，版本链的头节点就是当前记录最新的值。另外，每个版本中还包含生成该版本时对应的`事务id`

### ReadView

对于使用`READ UNCOMMITTED`隔离级别的事务来说，由于可以读到未提交事务修改过的记录，所以直接读取记录的最新版本就好了；对于使用`SERIALIZABLE`隔离级别的事务来说，设计`InnoDB`的大叔规定使用加锁的方式来访问记录, 对于使用`READ COMMITTED`和`REPEATABLE READ`隔离级别的事务来说，都必须保证读到已经提交了的事务修改过的记录，也就是说假如另一个事务已经修改了记录但是尚未提交，是不能直接读取最新版本的记录的，核心问题就是：需要判断一下版本链中的哪个版本是当前事务可见的

因此提出了ReadView的概念

- `m_ids`：表示在生成`ReadView`时当前系统中活跃的读写事务的`事务id`列表。

- `min_trx_id`：表示在生成`ReadView`时当前系统中活跃的读写事务中最小的`事务id`，也就是`m_ids`中的最小值。

- `max_trx_id`：表示生成`ReadView`时系统中应该分配给下一个事务的`id`值。

- `creator_trx_id`：表示生成该`ReadView`的事务的`事务id`。

  > 只有在对表中的记录做改动时（执行INSERT、DELETE、UPDATE这些语句时）才会为事务分配事务id，否则在一个只读事务中的事务id值都默认为0

执行SELECT时会生成ReadView, 那么被访问版本的` trx_id `和上述四个值进行对比, 就可以判读哪个版本是当前事务可见的.

1. `trx_id`  =  `creator_trx_id`：意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。
2. `trx_id `  <  `min_trx_id`：表明生成该版本的事务在当前事务生成`ReadView`前已经提交，所以该版本可以被当前事务访问
3. `trx_id `  ∈ [`min_trx_id` , `max_trx_id`): 那就需要判断一下`trx_id`属性值是不是在`m_ids`列表中，如果在，说明创建`ReadView`时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建`ReadView`时生成该版本的事务已经被提交，该版本可以被访问
4. `trx_id `  >=  `max_trx_id`: 表明生成该版本的事务在当前事务生成`ReadView`后才开启，所以该版本不可以被当前事务访问。

### 总结

`MVCC`（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用`READ COMMITTD`、`REPEATABLE READ`这两种隔离级别的事务在执行普通的`SELECT`操作时访问记录的版本链的过程，这样子可以使不同事务的`读-写`、`写-读`操作并发执行，从而提升系统性能。

> `READ COMMITTD`、`REPEATABLE READ`这两个隔离级别的一个很大不同就是：生成`ReadView `的时机不同，`READ COMMITTD`在每一次进行普通SELECT操作前都会生成一个`ReadView`，而`REPEATABLE READ`只在第一次进行普通SELECT操作前生成一个`ReadView`，之后的查询操作都重复使用这个`ReadView`就好了。

# 锁

## 锁的分类

### 全局锁

全局锁主要用于全库逻辑备份.

``` sql
flush tables with read lock // 加全局锁
	
unlock tables				// 解锁
```

> 全局锁缺点

加上全局锁，意味着整个数据库都是只读状态。

那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。

> 既然备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免？

当处于可重复读隔离级别下, 在备份前先开启事务并创建Read View, 然后整个业务执行期间都使用这个ReadView, 借助MVCC, 备份期间依然可以对数据进行更新

### 表级锁

#### 表锁

``` sql
//表级别的共享锁，也就是读锁；
lock tables t_student read;

//表级别的独占锁，也就是写锁；
lock tables t_stuent write;

//解锁
unlock tables
```

需要注意的是，表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。

也就是说如果本线程对学生表加了「共享表锁」，那么本线程接下来如果要对学生表执行写操作的语句，是会被阻塞的，当然其他线程对学生表进行写操作时也会被阻塞，直到锁被释放。

#### 意向锁

- 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；
- 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；

也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。

而普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的。

不过，select 也是可以对记录加共享锁和独占锁的，具体方式如下：

```sql
//先在表上加上意向共享锁，然后对读取的记录加共享锁
select ... lock in share mode;

//先表上加上意向独占锁，然后对读取的记录加独占锁
select ... for update;
```

**意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（\*lock tables ... read\*）和独占表锁（\*lock tables ... write\*）发生冲突。**

表锁和行锁是满足读读共享、读写互斥、写写互斥的。

如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。

那么有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。

所以，**意向锁的目的是为了快速判断表里是否有记录被加锁**。



#### 元数据锁

我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：

- 对一张表进行 CRUD 操作时，加的是 **MDL 读锁**；
- 对一张表做结构变更操作的时候，加的是 **MDL 写锁**；

MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。

当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。

反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。

> MDL 不需要显示调用，那它是在什么时候释放的?

MDL 是在事务提交后才会释放，这意味着**事务执行期间，MDL 是一直持有的**。

那如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），那在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景：

1. 首先，线程 A 先启用了事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁；
2. 然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突；
3. 接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞，

那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。

> 为什么线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞？

这是因为申请 MDL 锁的操作会形成一个队列，队列中**写锁获取优先级高于读锁**，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。

所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更

#### AUTO-INC锁

表里的主键通常都会设置成自增的，这是通过对主键字段声明 `AUTO_INCREMENT` 属性实现的。

之后可以在插入数据时，可以不指定主键的值，数据库会自动给主键赋值递增的值，这主要是通过 **AUTO-INC 锁**实现的。

AUTO-INC 锁是特殊的表锁机制，锁**不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放**。

**在插入数据时，会加一个表级别的 AUTO-INC 锁**，然后为被 `AUTO_INCREMENT` 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。

那么，一个事务在持有 AUTO-INC 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 `AUTO_INCREMENT` 修饰的字段的值是连续递增的。

 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种**轻量级的锁**来实现自增。

一样也是在插入数据的时候，会为被 `AUTO_INCREMENT` 修饰的字段加上轻量级锁，**然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁**。



### 行级锁

#### Record Lock

Record Lock 称为记录锁，锁住的是一条记录。而且记录锁是有 S 锁和 X 锁之分的：

- 当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）;
- 当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。

#### Gap Lock

Gap Lock 称为间隙锁，只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。

假设，表中有一个范围 id 为（3，5）间隙锁，那么其他事务就无法插入 id = 4 这条记录了，这样就有效的防止幻读现象的发生。

间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，**间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的**。

#### Next-Key Lock

**next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的**。

虽然相同范围的间隙锁是多个事务相互兼容的，但对于记录锁，我们是要考虑 X 型与 S 型关系，X 型的记录锁与 X 型的记录锁是冲突的。

#### 插入意向锁

一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。

如果有的话，插入操作就会发生**阻塞**，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个**插入意向锁**，表明有事务想在某个区间插入新记录，但是现在处于等待状态。

> *MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁*

插入意向锁名字虽然有意向锁，但是它并**不是意向锁，它是一种特殊的间隙锁，属于行级别锁**。

如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。

插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。

# MySQL日志

## Buffer Pool

为了避免频繁的磁盘IO, InnoDB设计了一个缓冲池, 来提高数据库的读写性能

- 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。
- 当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。

在 MySQL 启动的时候，**InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的`16KB`的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页**。MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，申请物理内存，接着将虚拟地址和物理地址建立映射关系

![img](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\bufferpool内容.drawio.png)

> Undo 页是记录什么？

开启事务后,  InnoDB层更新记录前, 需要先记录相应的undo log. undo log会写入Buffer Pool中的undo页面

> 查询一条记录，就只需要缓冲一条记录吗？

当查询一条记录时, InnoDB会把整页的数据加载到Buffer Pool中, 再通过页里的页目录去定位到某条具体的记录

## undo log

在增删改时, MySQL会隐式开启事务, 为了保证事务的原子性(如果事务还没提交, 发生了崩溃, 需要回滚数据), 那么在事务执行过程中, 记录下回滚时需要的信息到日志里, 这个日志就是undo log

 ![回滚事务](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\回滚事务.png)

- 插入: 主要记录这条记录的主键值

- 删除: 把这条记录中的内容都记录下来

- 更新: 把被更新的列的旧值记录下来(分为更新主键和非更新主键)

  > 更新主键的情况, 需要更改原纪录的delete mark, 再插入一条新纪录, 所以这种情况会记录两条undo log
  >
  > 非更新主键, 如果更新列里的值跟旧值所占存储空间一样大小, 则就地更新. 如果不一样大小, 则这里是把这条记录从`正常记录链表`中移除并加入到`垃圾链表`中，并且修改页面中相应的统计信息. 这里如果新创建的记录占用的存储空间大小不超过旧记录占用的空间，那么可以直接重用被加入到`垃圾链表`中的旧记录所占用的存储空间，否则的话需要在页面中新申请一段空间以供新记录使用，如果本页面内已经没有可用的空间的话，那就需要进行页面分裂操作，然后再插入新记录

一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id：

- 通过 trx_id 可以知道该记录是被哪个事务修改的；
- 通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链；



因此undo log有两大作用:

1. 实现事务回滚, 保障事务的原子性
2. 实现MVCC(多版本并发控制)的关键因素之一

> undo log 是如何刷盘（持久化到磁盘）的
>
> undo log 和数据页的刷盘策略是一样的, 都需要redo log保证持久化
>
> buffer Pool中有undo页, 对undo页的修改也会记录到redolog, 依靠redolog保证持久化. 5.5之后默认写到.ibdata文件(共享表数据文件)

## redo log

为了保证Buffer Pool里数据的持久化, 需要有一个日志来记录Buffer Pool里面的更新, 这个日志就是redo log

为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，**这个时候更新就算完成了**。

后续，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 **WAL （Write-Ahead Logging）技术**。

**WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上**性能调优

![img](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\wal.png)

> 什么是redo log

redo log 是物理日志, 用来记录事务在某个数据页做了什么修改.

在事务提交时, 只需要将redo log落盘就可以了, 不需要把Buffer Pool里的脏页持久化到磁盘. 那么当系统崩溃时, 如果脏页还没落盘, 但是redo log已经持久化了, MySQL重启后就可以根据redo log里的内容恢复数据

> 数据本来就要落盘, 为什么需要redo log

1. 首先是因为将写操作从随机写变为了顺序写, 写入脏页需要先找到写入位置, 然后才写到磁盘, 属于随机写, 而redo log使用了追加操作, 所以磁盘操作时顺序写, redo log写入磁盘的开销更小
2. 实现事务的持久性, 能够保证MySQL在任何时间段突然崩溃, 重启后已提交的记录不会丢失
3. 不止记录需要持久化, 有的共享表数据也需要持久化, 比如undo log, undo log 一开始是写在Buffer Pool的undo页面, 需要redo log来保证落盘

> 被修改 Undo 页面，需要记录对应 redo log 吗？

需要的。

开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。

不过，**在内存修改该 Undo 页面后，需要记录对应的 redo log**。

> redo log 和 undo log的区别

这两种都是InnoDB的日志, 区别在于:

- undo log 记录了此次事务「**开始前**」的数据状态，记录的是更新**之前**的值；
- redo log 记录了此次事务「**完成后**」的数据状态，记录的是更新**之后**的值；

![事务恢复](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\事务恢复.png)

有了redo log, 在通过WAL技术, InnoDB能保证即使数据库发生异常重启, 之前提交的记录不会丢失, 这个能力称为crash-safe(崩溃恢复) . 因此redo log保证了事务四大特性的持久性

> 产生的 redo log 是直接写入磁盘的吗？

不是的。

实际上， 执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I/O 操作，而且磁盘的运行速度远慢于内存。

所以，redo log 也有自己的缓存—— **redo log buffer**，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘. 和Buffer Pool是不同的组件

### redo log 刷盘时机

主要有以下几个时机:

- MySQL正常关闭时
- 当redo log buffer 中记录的写入量大于redo log buffer 内存空间的一半是, 会触发落盘
- InnoDB的后台线程每隔一秒, 会将redo log buffer 持久化到磁盘
- 默认每次事务提交时会将缓存中redo log buffer里的redo log直接持久化到磁盘(策略由innodb_flush_log_at_trx_commit参数控制)

> innodb_flush_log_at_trx_commit 参数控制的是什么？

参数默认为1, 此时单独执行一个更新语句的时候，InnoDB 引擎会自己启动一个事务，在执行更新语句的过程中，生成的 redo log 先写入到 redo log buffer 中，然后等事务提交的时候，再将缓存在 redo log buffer 中的 redo log 按组的方式「顺序写」到磁盘。

- 为0时, 每次事务提交, redo log 留在redo log buffer, 该模式事务提交不会主动触发写入磁盘的操作
- 参数为1时, 每次事务提交时都会落盘
- 参数为2时, 每次事务提交都将redo log buffer 中的redo log 写到操作系统中page cache中的 redo log 文件, 由操作系统负责落盘

![img](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\innodb_flush_log_at_trx_commit.drawio.png)



> innodb_flush_log_at_trx_commit 为 0 和 2 的时候，什么时候才将 redo log 写入磁盘？

InnoDB的后台线程每隔一秒:

- 针对参数 0 ：会把缓存在 redo log buffer 中的 redo log ，通过调用 `write()` 写到操作系统的 Page Cache，然后调用 `fsync()` 持久化到磁盘。**所以参数为 0 的策略，MySQL 进程的崩溃会导致上一秒钟所有事务数据的丢失**;
- 针对参数 2 ：调用 fsync，将缓存在操作系统中 Page Cache 里的 redo log 持久化到磁盘。**所以参数为 2 的策略，较取值为 0 情况下更安全，因为 MySQL 进程的崩溃并不会丢失数据，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失**。

![img](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\innodb_flush_log_at_trx_commit2.drawio.png)

> 三个参数应用场景是什么?

- 数据安全性：参数 1 > 参数 2 > 参数 0
- 写入性能：参数 0 > 参数 2> 参数 1
- 所以，数据安全性和写入性能是熊掌不可得兼的，**要不追求数据安全性，牺牲性能；要不追求性能，牺牲数据安全性**。
  - 在一些对数据安全性要求比较高的场景中，显然 `innodb_flush_log_at_trx_commit` 参数需要设置为 1。
  - 在一些可以容忍数据库崩溃时丢失 1s 数据的场景中，我们可以将该值设置为 0，这样可以明显地减少日志同步到磁盘的 I/O 操作。
  - 安全性和性能折中的方案就是参数 2，虽然参数 2 没有参数 0 的性能高，但是数据安全性方面比参数 0 强，因为参数 2 只要操作系统不宕机，即使数据库崩溃了，也不会丢失数据，同时性能方便比参数 1 高。

### redo log 文件写满了怎么办

默认情况下， InnoDB 存储引擎有 1 个重做日志文件组( redo log Group），「重做日志文件组」由有 2 个 redo log 文件组成，这两个 redo 日志的文件名叫 ：`ib_logfile0` 和 `ib_logfile1` 。

在重做日志组中，每个 redo log File 的大小是固定且一致的，假设每个 redo log File 设置的上限是 1 GB，那么总共就可以记录 2GB 的操作。

重做日志文件组是以**循环写**的方式工作的

如果 write pos 追上了 checkpoint，就意味着 **redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞**（*因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要*），此时**会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针）**，然后 MySQL 恢复正常运行，继续执行新的更新操作。

## bin log

### redo log 和 binlog 有什么区别？

*1、适用对象不同：*

- binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；
- redo log 是 Innodb 存储引擎实现的日志；

*2、文件格式不同：*

- binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：
  - STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；
  - ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；
  - MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；
- redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；

*3、写入方式不同：*

- binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。
- redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。

*4、用途不同：*

- binlog 用于备份恢复、主从复制；
- redo log 用于掉电等故障恢复。

### 主从复制是怎么实现的

MySQL 集群的主从复制过程梳理成 3 个阶段：

- **写入 Binlog**：主库写 binlog 日志，提交事务，并更新本地存储数据。
- **同步 Binlog**：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。
- **回放 Binlog**：回放 binlog，并更新存储引擎中的数据。

具体详细过程如下：

- MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。
- 从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。
- 从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。

在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。

![MySQL 主从架构](F:\Note\实习冲刺\MySQL\MySQL学习笔记.assets\主从架构.drawio.png)



## * 两阶段提交







# 性能调优

## explain执行计划

在SQL语句前使用explain关键字可以输出执行计划

| **列名**        | **描述**                                                   |
| --------------- | ---------------------------------------------------------- |
| `id`            | 在一个大的查询语句中每个`SELECT`关键字都对应一个唯一的`id` |
| `select_type`   | `SELECT`关键字对应的那个查询的类型                         |
| `table`         | 表名                                                       |
| `partitions`    | 匹配的分区信息                                             |
| `type`          | 针对单表的访问方法                                         |
| `possible_keys` | 可能用到的索引                                             |
| `key`           | 实际上使用的索引                                           |
| `key_len`       | 实际使用到的索引长度                                       |
| `ref`           | 当使用索引列等值查询时，与索引列进行等值匹配的对象信息     |
| `rows`          | 预估的需要读取的记录条数                                   |
| `filtered`      | 某个表经过搜索条件过滤后剩余记录条数的百分比               |
| `Extra`         | 一些额外的信息                                             |

以下是对查询语句的列名详解

### table

不管查询语句多么复杂,最后的粒度也是到单表里面去访问, table列代表该表的表名

### id

一般来说一个select对应一个id.

如果一条查询出现多个select关键字:

- 查询中包含子查询的情况

  比如下边这个查询语句中就包含2个`SELECT`关键字：

  ```sql
  SELECT * FROM s1 
      WHERE key1 IN (SELECT key3 FROM s2);
  ```

- 查询中包含`UNION`语句的情况

  比如下边这个查询语句中也包含2个`SELECT`关键字：

  ```sql
  SELECT * FROM s1  UNION SELECT * FROM s2;
  ```

查询每出现一个select关键字，会分配一个唯一的id值，对于连接查询， 一个select关键字后面的from子句可以跟随多个表， 每个表对应一条记录，但是这些记录id值都是相同的：

``` sql
mysql> EXPLAIN SELECT * FROM s1 INNER JOIN s2;
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                                 |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+
|  1 | SIMPLE      | s1    | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 9688 |   100.00 | NULL                                  |
|  1 | SIMPLE      | s2    | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 9954 |   100.00 | Using join buffer (Block Nested Loop) |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+
2 rows in set, 1 warning (0.01 sec)
```

对于出现多个select关键字的查询语句, 一般来说一个select对应一个id,但有时查询优化器可能对设计子查询的查询语句进行重写, 转化为连接查询,  是否转换就看执行计划, 原则暂时不用在意

对于union子句的查询语句, 会有些特殊的地方:

``` sql
mysql> EXPLAIN SELECT * FROM s1  UNION SELECT * FROM s2;
+----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+
| id | select_type  | table      | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra           |
+----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+
|  1 | PRIMARY      | s1         | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 9688 |   100.00 | NULL            |
|  2 | UNION        | s2         | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 9954 |   100.00 | NULL            |
| NULL | UNION RESULT | <union1,2> | NULL       | ALL  | NULL          | NULL | NULL    | NULL | NULL |     NULL | Using temporary |
+----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+
3 rows in set, 1 warning (0.00 sec)
```

`MySQL`使用的是内部的临时表。正如上边的查询计划中所示，`UNION`子句是为了把`id`为`1`的查询和`id`为`2`的查询的结果集合并起来并去重，所以在内部创建了一个名为`<union1, 2>`的临时表（就是执行计划第三条记录的`table`列的名称），`id`为`NULL`表明这个临时表是为了合并两个查询的结果集而创建的。

跟`UNION`对比起来，`UNION ALL`就不需要为最终的结果集进行去重，它只是单纯的把多个查询的结果集中的记录合并成一个并返回给用户，所以也就不需要使用临时表

### select_type

| **名称**               | **描述**                                                     |
| ---------------------- | ------------------------------------------------------------ |
| `SIMPLE`               | Simple SELECT (not using UNION or subqueries)                |
| `PRIMARY`              | Outermost SELECT                                             |
| `UNION`                | Second or later SELECT statement in a UNION                  |
| `UNION RESULT`         | Result of a UNION                                            |
| `SUBQUERY`             | First SELECT in subquery                                     |
| `DEPENDENT SUBQUERY`   | First SELECT in subquery, dependent on outer query           |
| `DEPENDENT UNION`      | Second or later SELECT statement in a UNION, dependent on outer query |
| `DERIVED`              | Derived table                                                |
| `MATERIALIZED`         | Materialized subquery                                        |
| `UNCACHEABLE SUBQUERY` | A subquery for which the result cannot be cached and must be re-evaluated for each row of the outer query |
| `UNCACHEABLE UNION`    | The second or later select in a UNION that belongs to an uncacheable subquery (see UNCACHEABLE SUBQUERY) |

- `SIMPLE`

  查询语句不包含UNION或者子查询的查询都是SIMPLE类型

- `PRIMARY`

  对于包含`UNION`、`UNION ALL`或者子查询的大查询来说，它是由几个小查询组成的，其中最左边的那个查询的`select_type`值就是`PRIMARY`

- `UNION`

  对于包含`UNION`或者`UNION ALL`的大查询来说，它是由几个小查询组成的，其中除了最左边的那个小查询以外，其余的小查询的`select_type`值就是`UNION`

- `UNION RESULT`

  `MySQL`选择使用临时表来完成`UNION`查询的去重工作，针对该临时表的查询的`select_type`就是`UNION RESULT`

- `SUBQUERY`

  如果包含子查询的查询语句不能够转为对应的`semi-join`的形式，并且该子查询是不相关子查询，并且查询优化器决定采用将该子查询物化的方案来执行该子查询时，该子查询的第一个`SELECT`关键字代表的那个查询的`select_type`就是`SUBQUERY`. 物化是一种将子查询结果存储在临时表中的技术，以提高性能，但也会增加存储和维护的开销。需要注意的是，由于select_type为SUBQUERY的子查询会被物化，所以只需要执行一遍

- `DEPENDENT SUBQUERY`

  如果包含子查询的查询语句不能够转为对应的`semi-join`的形式，并且该子查询是相关子查询，则该子查询的第一个`SELECT`关键字代表的那个查询的`select_type`就是`DEPENDENT SUBQUERY`, select_type为DEPENDENT SUBQUERY的查询可能会被执行多次。

- `DEPENDENT UNION`

  在包含`UNION`或者`UNION ALL`的大查询中，如果各个小查询都依赖于外层查询的话，那除了最左边的那个小查询之外，其余的小查询的`select_type`的值就是`DEPENDENT UNION`:

  ``` sql
  mysql> EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2 WHERE key1 = 'a' UNION SELECT key1 FROM s1 WHERE key1 = 'b');
  +----+--------------------+------------+------------+------+---------------+----------+---------+-------+------+----------+--------------------------+
  | id | select_type        | table      | partitions | type | possible_keys | key      | key_len | ref   | rows | filtered | Extra                    |
  +----+--------------------+------------+------------+------+---------------+----------+---------+-------+------+----------+--------------------------+
  |  1 | PRIMARY            | s1         | NULL       | ALL  | NULL          | NULL     | NULL    | NULL  | 9688 |   100.00 | Using where              |
  |  2 | DEPENDENT SUBQUERY | s2         | NULL       | ref  | idx_key1      | idx_key1 | 303     | const |   12 |   100.00 | Using where; Using index |
  |  3 | DEPENDENT UNION    | s1         | NULL       | ref  | idx_key1      | idx_key1 | 303     | const |    8 |   100.00 | Using where; Using index |
  | NULL | UNION RESULT       | <union2,3> | NULL       | ALL  | NULL          | NULL     | NULL    | NULL  | NULL |     NULL | Using temporary          |
  +----+--------------------+------------+------------+------+---------------+----------+---------+-------+------+----------+--------------------------+
  4 rows in set, 1 warning (0.03 sec)
  ```

  查询里包含了一个子查询，子查询里又是由`UNION`连起来的两个小查询。从执行计划中可以看出来，`SELECT key1 FROM s2 WHERE key1 = 'a'`这个小查询由于是子查询中第一个查询，所以它的`select_type`是`DEPENDENT SUBQUERY`，而`SELECT key1 FROM s1 WHERE key1 = 'b'`这个查询的`select_type`就是`DEPENDENT UNION`

- `DRIVED`

  对于采用物化的方式执行的包含派生表的查询，该派生表对应的子查询的`select_type`就是`DERIVED`

- `MATERIALIZED`

  当查询优化器在执行包含子查询的语句时，选择将子查询物化之后与外层查询进行连接查询时，该子查询对应的`select_type`属性就是`MATERIALIZED`

- `UNCACHEABLE SUBQUERY`和`UNCACHEABLE UNION`

  不常用

### partitions

一般情况下查询语句的执行计划partition值都是NULL

### type

- system

  当表中只有一条记录并且该表使用的存储引擎的统计数据是精确的，比如MyISAM、Memory，那么对该表的访问方法就是`system`

- const

  当我们根据主键或者唯一二级索引列与常数进行等值匹配时，对单表的访问方法就是`const`

- eq_ref

  连接查询时，如果被驱动表是通过主键或者唯一二级索引列等值匹配的方式进行访问的（如果该主键或者唯一二级索引是联合索引的话，所有的索引列都必须进行等值比较），则对该被驱动表的访问方法就是`eq_ref`

- ref

  当通过普通的二级索引列与常量进行等值匹配时来查询某个表，那么对该表的访问方法就可能是`ref`

- fulltext

  全文索引

- ref_or_null

  当对普通二级索引进行等值匹配查询，该索引列的值也可以是`NULL`值时，那么对该表的访问方法就可能是`ref_or_null`

- index_merge

  一般情况下对于某个表的查询只能使用到一个索引，但单表访问方法时在某些场景下可以使用`Intersection`、`Union`、`Sort-Union`这三种索引合并的方式来执行查询

- unique_subquery

  类似于两表连接中被驱动表的`eq_ref`访问方法，`unique_subquery`是针对在一些包含`IN`子查询的查询语句中，如果查询优化器决定将`IN`子查询转换为`EXISTS`子查询，而且子查询可以使用到主键进行等值匹配的话，那么该子查询执行计划的`type`列的值就是`unique_subquery`

- index_subquery

  `index_subquery`与`unique_subquery`类似，只不过访问子查询中的表时使用的是普通的索引

- range

  如果使用索引获取某些`范围区间`的记录，那么就可能使用到`range`访问方法

- index

  当我们可以使用索引覆盖，但需要扫描全部的索引记录时，该表的访问方法就是`index`

- ALL

  全表扫描

一般来说，这些访问方法按照我们介绍它们的顺序性能依次变差。其中除了`All`这个访问方法外，其余的访问方法都能用到索引，除了`index_merge`访问方法外，其余的访问方法都最多只能用到一个索引。

### possible_key和key

`possible_keys`列表示在某个查询语句中，对某个表执行单表查询时可能用到的索引有哪些，`key`列表示实际用到的索引有哪些

不过有一点比较特别，就是在使用`index`访问方法来查询某个表时，`possible_keys`列是空的，而`key`列展示的是实际使用到的索引

另外需要注意的一点是，possible_keys列中的值并不是越多越好，可能使用的索引越多，查询优化器计算查询成本时就得花费更长时间，所以如果可以的话，尽量删除那些用不到的索引

### key_len

`key_len`列表示当优化器决定使用某个索引执行查询时，该索引记录的最大长度，它是由这三个部分构成的：

- 对于使用固定长度类型的索引列来说，它实际占用的存储空间的最大长度就是该固定值，对于指定字符集的变长类型的索引列来说，比如某个索引列的类型是`VARCHAR(100)`，使用的字符集是`utf8`，那么该列实际占用的最大存储空间就是`100 × 3 = 300`个字节。
- 如果该索引列可以存储`NULL`值，则`key_len`比不可以存储`NULL`值时多1个字节。
- 对于变长字段来说，都会有2个字节的空间来存储该变长列的实际长度

因此值为三个部分相加

### ref

当使用索引列等值匹配的条件去执行查询时，也就是在访问方法是`const`、`eq_ref`、`ref`、`ref_or_null`、`unique_subquery`、`index_subquery`其中之一时，`ref`列展示的就是与索引列作等值匹配的东东是个啥，比如只是一个常数或者是某个列

### rows

如果查询优化器决定使用全表扫描的方式对某个表执行查询时，执行计划的`rows`列就代表预计需要扫描的行数，如果使用索引来执行查询时，执行计划的`rows`列就代表预计扫描的索引记录行数

### filtered

就是预估需要搜索的记录在需要查的总量的百分比

### extra

- `No tables used`

  当查询语句的没有`FROM`子句时将会提示该额外信息

- `Impossible WHERE`

  查询语句的`WHERE`子句永远为`FALSE`时将会提示该额外信息

- `No matching min/max row`

  当查询列表处有`MIN`或者`MAX`聚集函数，但是并没有符合`WHERE`子句中的搜索条件的记录时，将会提示该额外信息

- `Using index`

  当我们的查询列表以及搜索条件中只包含属于某个索引的列，也就是在可以使用索引覆盖的情况下，在`Extra`列将会提示该额外信息

- `Using index condition`

  有些搜索条件中虽然出现了索引列，但却并不能用来形成范围区间，也就是不能被用来减少需要扫描的记录数量

- `Using where`

  当某个搜索条件需要在`server层`进行判断时，在`Extra`列中会提示`Using where`

- `Using join buffer (Block Nested Loop)`

  在连接查询执行过程中，当被驱动表不能有效的利用索引加快访问速度，`MySQL`一般会为其分配一块名叫`join buffer`的内存块来加快查询速度，也就是我们所讲的`基于块的嵌套循环算法`

- `Not exists`

  当我们使用左（外）连接时，如果`WHERE`子句中包含要求被驱动表的某个列等于`NULL`值的搜索条件，而且那个列又是不允许存储`NULL`值的，那么在该表的执行计划的`Extra`列就会提示`Not exists`额外信息

- `Using intersect(...)`、`Using union(...)`和`Using sort_union(...)`

  如果执行计划的`Extra`列出现了`Using intersect(...)`提示，说明准备使用`Intersect`索引合并的方式执行查询，括号中的`...`表示需要进行索引合并的索引名称；如果出现了`Using union(...)`提示，说明准备使用`Union`索引合并的方式执行查询；出现了`Using sort_union(...)`提示，说明准备使用`Sort-Union`索引合并的方式执行查询

## optimizer trace

优化过程大致分为了三个阶段：

- `prepare`阶段
- `optimize`阶段
- `execute`阶段

我们所说的基于成本的优化主要集中在`optimize`阶段，对于单表查询来说，我们主要关注`optimize`阶段的`"rows_estimation"`这个过程，这个过程深入分析了对单表查询的各种执行方案的成本；对于多表连接查询来说，我们更多需要关注`"considered_execution_plans"`这个过程，这个过程里会写明各种不同的连接方式所对应的成本。反正优化器最终会选择成本最低的那种方案来作为最终的执行计划，也就是我们使用`EXPLAIN`语句所展现出的那种方案。

## SQL优化



